"""
Content processor for converting various file types to Qiita-compatible markdown
"""
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import markdown
import logging

from .security_scanner import SecurityScanner, SecurityIssue

logger = logging.getLogger(__name__)

class ContentProcessor:
    """Process file content for Qiita upload with security scanning"""
    
    def __init__(self, enable_security_scan: bool = True, security_config_file: str = None):
        self.processors = {
            '.md': self._process_markdown,
            '.py': self._process_python,
            '.js': self._process_javascript,
            '.ts': self._process_typescript,
            '.txt': self._process_text,
            '.rst': self._process_rst
        }
        self.enable_security_scan = enable_security_scan
        
        if enable_security_scan:
            config_path = security_config_file or "config/security_rules.json"
            self.security_scanner = SecurityScanner(config_path)
        else:
            self.security_scanner = None
    
    def process_file(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]], Optional[Dict]]:
        """
        Process a file and return (title, body, tags, security_report)
        """
        path = Path(file_path)
        extension = path.suffix.lower()
        
        if extension not in self.processors:
            title, body, tags = self._process_generic(file_path)
        else:
            title, body, tags = self.processors[extension](file_path)
        
        # Perform security scan
        security_report = None
        if self.enable_security_scan and self.security_scanner:
            security_report = self._perform_security_scan(body, file_path)
        
        return title, body, tags, security_report
    
    def _perform_security_scan(self, content: str, file_path: str) -> Dict:
        """Perform security scan on content"""
        try:
            issues = self.security_scanner.scan_content(content, file_path)
            report = self.security_scanner.get_security_report(issues)
            
            logger.info(f"Security scan completed for {file_path}: {report['total_issues']} issues found")
            
            return report
        except Exception as e:
            logger.error(f"Security scan failed for {file_path}: {e}")
            return {
                "status": "error",
                "message": f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}",
                "total_issues": 0
            }
    
    def should_block_upload(self, security_report: Optional[Dict]) -> bool:
        """Check if upload should be blocked based on security report"""
        if not security_report or not self.security_scanner:
            return False
        
        return security_report.get("status") == "critical"
    
    def add_security_warning_to_content(self, body: str, security_report: Dict) -> str:
        """Add security warning to content if issues found"""
        if not security_report or security_report.get("total_issues", 0) == 0:
            return body
        
        warning_section = self._generate_security_warning_section(security_report)
        
        # Add warning at the beginning of the content
        return f"{warning_section}\n\n{body}"
    
    def _generate_security_warning_section(self, security_report: Dict) -> str:
        """Generate security warning section for content"""
        if security_report.get("status") == "critical":
            warning_icon = "ðŸš¨"
            warning_level = "é‡è¦"
        elif security_report.get("status") == "high":
            warning_icon = "âš ï¸"
            warning_level = "æ³¨æ„"
        else:
            warning_icon = "ðŸ’¡"
            warning_level = "æƒ…å ±"
        
        warning = f"""
{warning_icon} **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£{warning_level}**

ã“ã®è¨˜äº‹ã«ã¯ä»¥ä¸‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹é …ç›®ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š

"""
        
        # Add issue summary
        if "by_category" in security_report:
            for category, count in security_report["by_category"].items():
                category_name = self._get_category_japanese_name(category)
                warning += f"- {category_name}: {count}ä»¶\n"
        
        warning += """
è¨˜äº‹ã®å†…å®¹ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ä»¥ä¸‹ã®å¯¾å¿œã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
- å®Ÿéš›ã®èªè¨¼æƒ…å ±ã‚„APIã‚­ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
- å€‹äººæƒ…å ±ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã€é›»è©±ç•ªå·ç­‰ï¼‰ã®åŒ¿ååŒ–
- å±é™ºãªã‚³ãƒ¼ãƒ‰ä¾‹ã«ã¯é©åˆ‡ãªè­¦å‘Šã‚’è¿½åŠ 

---
"""
        
        return warning
    
    def _get_category_japanese_name(self, category: str) -> str:
        """Get Japanese name for security category"""
        category_names = {
            "credentials": "èªè¨¼æƒ…å ±",
            "personal_info": "å€‹äººæƒ…å ±",
            "dangerous_code": "å±é™ºãªã‚³ãƒ¼ãƒ‰",
            "web_security": "Webã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
            "file_paths": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
            "network_info": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æƒ…å ±"
        }
        return category_names.get(category, category)
    
    def _read_file_content(self, file_path: str) -> str:
        """Read file content with encoding detection"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='shift_jis') as f:
                return f.read()
    
    def _extract_title_from_content(self, content: str, filename: str) -> str:
        """Extract title from content or use filename"""
        lines = content.strip().split('\n')
        
        # Look for markdown title
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        
        # Look for docstring or comment title
        title_patterns = [
            r'^"""([^"]+)"""',  # Python docstring
            r'^/\*\*\s*([^*]+)\s*\*/',  # JS/TS comment
            r'^#\s*(.+)$',  # Comment line
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, content, re.MULTILINE)
            if match:
                return match.group(1).strip()
        
        # Use filename as fallback
        return Path(filename).stem.replace('_', ' ').replace('-', ' ').title()
    
    def _process_markdown(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process markdown file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        # Extract tags from front matter or content
        tags = self._extract_tags_from_content(content)
        
        # Add timestamp
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        body = f"{content}\n\n---\n*Last updated: {timestamp}*\n*Source: {Path(file_path).name}*"
        
        return title, body, tags
    
    def _process_python(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process Python file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        # Create markdown with code block
        body = f"""# {title}

Pythonã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}`

```python
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "Python", "versions": []}]
        return title, body, tags
    
    def _process_javascript(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process JavaScript file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        body = f"""# {title}

JavaScriptã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}`

```javascript
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "JavaScript", "versions": []}]
        return title, body, tags
    
    def _process_typescript(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process TypeScript file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        body = f"""# {title}

TypeScriptã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}`

```typescript
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "TypeScript", "versions": []}]
        return title, body, tags
    
    def _process_text(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process plain text file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        body = f"""# {title}

ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}`

```
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "å‚™å¿˜éŒ²", "versions": []}]
        return title, body, tags
    
    def _process_rst(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process reStructuredText file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        
        # Convert to markdown-style
        body = f"""# {title}

reStructuredTextãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}`

```rst
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ", "versions": []}]
        return title, body, tags
    
    def _process_generic(self, file_path: str) -> Tuple[str, str, List[Dict[str, str]]]:
        """Process generic file"""
        content = self._read_file_content(file_path)
        title = self._extract_title_from_content(content, file_path)
        extension = Path(file_path).suffix
        
        body = f"""# {title}

ãƒ•ã‚¡ã‚¤ãƒ«: `{Path(file_path).name}` ({extension})

```
{content}
```

---
*Last updated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*Source: {Path(file_path).name}*
"""
        
        tags = [{"name": "ãã®ä»–", "versions": []}]
        return title, body, tags
    
    def _extract_tags_from_content(self, content: str) -> List[Dict[str, str]]:
        """Extract tags from content"""
        tags = []
        
        # Look for YAML front matter
        if content.startswith('---'):
            end_marker = content.find('---', 3)
            if end_marker != -1:
                front_matter = content[3:end_marker]
                tag_match = re.search(r'tags:\s*\[(.*?)\]', front_matter)
                if tag_match:
                    tag_names = [tag.strip().strip('"\'') for tag in tag_match.group(1).split(',')]
                    tags = [{"name": name, "versions": []} for name in tag_names if name]
        
        # Default tags if none found
        if not tags:
            tags = [{"name": "å‚™å¿˜éŒ²", "versions": []}]
            
        return tags